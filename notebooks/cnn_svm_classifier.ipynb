{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load and preprocess data\n",
        "\n",
        "Load the CIFAR-10 dataset and preprocess the data by scaling the pixel values to be between 0 and 1 and converting the class labels to one-hot encoded vectors"
      ],
      "metadata": {
        "id": "O6VopT9VIlr4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "R7r0mf_7WIy_"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Preprocess data\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the model architecture\n",
        "\n",
        "Define a convolutional neural network (CNN) model with four convolutional layers and two fully connected layers."
      ],
      "metadata": {
        "id": "mh9yMJ_mIu5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=x_train.shape[1:]))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYRF6z04WNlK",
        "outputId": "0a125f04-01f3-4175-fd13-a6c6425cdc81"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               1180160   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile and fit the model\n",
        "\n",
        "Compile the model with categorical cross-entropy loss and the Adam optimizer. Then, fit the model on the training data with a batch size of 64, for 10 epochs. Use the test set for validation."
      ],
      "metadata": {
        "id": "0afDejs7JCB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMlJ9IsFWfo5",
        "outputId": "462be391-3722-4d77-a07f-1868b180ce6a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 10s 9ms/step - loss: 1.3750 - accuracy: 0.5055 - val_loss: 1.0526 - val_accuracy: 0.6268\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.9237 - accuracy: 0.6758 - val_loss: 0.8686 - val_accuracy: 0.6945\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.7288 - accuracy: 0.7452 - val_loss: 0.7542 - val_accuracy: 0.7379\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.5751 - accuracy: 0.7998 - val_loss: 0.7260 - val_accuracy: 0.7516\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4445 - accuracy: 0.8432 - val_loss: 0.7819 - val_accuracy: 0.7475\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.3214 - accuracy: 0.8858 - val_loss: 0.8125 - val_accuracy: 0.7566\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2232 - accuracy: 0.9214 - val_loss: 0.9595 - val_accuracy: 0.7463\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 0.1515 - accuracy: 0.9468 - val_loss: 1.1209 - val_accuracy: 0.7418\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.1198 - accuracy: 0.9588 - val_loss: 1.1803 - val_accuracy: 0.7422\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 0.1041 - accuracy: 0.9644 - val_loss: 1.3596 - val_accuracy: 0.7429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract features from the last fully connected layer\n",
        "\n",
        "Create a feature extractor by building a new model that takes the same input as the original model but outputs the activations of the second to last layer. Use this feature extractor to transform the training and test data into feature vectors."
      ],
      "metadata": {
        "id": "0HYCYRRqJK8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Extract features from last fully connected layer\n",
        "feature_extractor = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
        "x_train_features = feature_extractor.predict(x_train)\n",
        "x_test_features = feature_extractor.predict(x_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wd5kwGGpLl5u",
        "outputId": "c37d0871-0ba0-4467-fa64-81d27c07139a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 4s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train an SVM classifier\n",
        "\n",
        "Train a support vector machine (SVM) classifier with a linear kernel on the feature vectors extracted from the last fully connected layer of the CNN."
      ],
      "metadata": {
        "id": "IAEWOM8rJS_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train SVM classifier\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(x_train_features, np.argmax(y_train, axis=1))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "dfub9VjrIO2G",
        "outputId": "d25c9600-e164-4fac-c6f5-dcd93bf54fce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the model\n",
        "\n",
        "Evaluate the trained model on the test set by computing the accuracy of the SVM classifier on the extracted feature vectors of the test set."
      ],
      "metadata": {
        "id": "EK3m24anJc2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "test_acc = svm.score(x_test_features, np.argmax(y_test, axis=1))\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj6F9R7tIix4",
        "outputId": "0a559cfa-0d5e-493e-aab7-fb839b7db86a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.7493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Test the Trained Model on Multiple Images\n",
        "Load multiple test images, preprocess them, stack them into a single tensor, and use the trained model to predict the class labels of each image. The predicted class labels will be printed for each image."
      ],
      "metadata": {
        "id": "ps0HxPmWWLOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load the test images\n",
        "test_images = []\n",
        "for i in range(4):\n",
        "    img_path = f\"/content/image{i+1}.jpeg\"\n",
        "    img = image.load_img(img_path, target_size=(32, 32))\n",
        "    img = image.img_to_array(img)\n",
        "    img = img.astype('float32') / 255\n",
        "    test_images.append(img)\n",
        "\n",
        "# Stack the input images into a single tensor\n",
        "stacked_images = np.stack(test_images, axis=0)\n",
        "\n",
        "# Predict the classes of the stacked images\n",
        "class_idxs = np.argmax(model.predict(stacked_images), axis=1)\n",
        "\n",
        "# Print the predicted class labels for each image\n",
        "class_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "for i, class_idx in enumerate(class_idxs):\n",
        "    print(f\"Predicted class for image{i+1}: {class_labels[class_idx]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGYI9RgvK2aX",
        "outputId": "0db68ac9-3e4c-42d6-f45c-58b57296bd72"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 148ms/step\n",
            "Predicted class for image1: horse\n",
            "Predicted class for image2: airplane\n",
            "Predicted class for image3: deer\n",
            "Predicted class for image4: dog\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a requirement file"
      ],
      "metadata": {
        "id": "ShtEN41SJpJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt\n"
      ],
      "metadata": {
        "id": "DF6Tb4Bi_psz"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}